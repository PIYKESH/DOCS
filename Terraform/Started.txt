Terraform (IAC)
1-It is open source tool which helps for automating the infastructure.
2-It has declarative syntax and uses push based deployments.
3-Its code can be written in JSON or HCL(Hashicorp configuration language).
4-CORE COMPONENTS:-
  Executable-:This is a single binary file which is invoke to run terraform, It contains all the terraform functionality
  Congiuration files-:It may be single or multiple files with .tf extension where it combines all the file to work.
  Provider Plugins-:The provider plugins help to terraform to communicate with any service provider via API.For ex if terraform wants
                    to talk with AWS it will need a pluginn which is stored in terraform.registry.io .
  State Data-:Terraform keeps update of all conifg or version of provisioning any service provider by keeping a state file in repo.
5-Terraform Syntax or Object Refernce 
  <resource_type>.<name_label>.<attribute>
   EX- resource "aws_instance" "web server"{
        name = "Web Server"
		ebs volume ={
		size = "50"
		}
	}
6-INPUT_Variables
    input_variables------>local_values----->outputvalues
    (var_Syntax)
	variable "name_label"{}
	
	variable "name_label"{
	type = value
	description = "value"
	default = "value"
    sensitive =  true | false (Boolean Values)
	
  Examples
    variable = "aws_tag"{} (There is no use of argument)
     or
    variable = "aws_region"{
     type = "string"
	 description = "The region sepcified for the AWS"
	 default = "us-east-1"
	 sensitive = false (either you mention or don't mention it automatically takes the false value for true we have to define)
	 }
7-Date Types in Terraform
    Primitive:- string,number,boolean
	Collection:- list,set,map (Data-type must be same)
	Structural:- tuple,object (Data-type can be mixed)
	
  Examples
    variable = "aws_region"{         
	type = List(string)
	description = "The region sepcified for AWS"
	default = ["us-east-1","us-east-2","us-west-1","us-west-2"]
	}
	Calling or referencing any var.aws_region[0] Note:-0 is for ex it can any number.
	or
	variable = "aws_instance_sizes"{
	type = Map(string)
    description	= "Region to use for instances"
	default = {
	  small = "t2.micro"
	  medium = "t2.smmall"
	  Large = "t2.large"
	 }
	 }
	Referncing collecting values
	var.<name_label>.<key_name> or var.<name_label>.["key_name"]
	Calling any var.aws_instance.small or var.aws_instance.["small"]
8-Local Values
   locals {
   instance_prefix = "Globo"
   comman_tags= {
    company = "Natgeo"
    project = "var.project"
	billing_code = "var.billing.code"
   }
   }
  Terraform_local_refernce
    local.<name_label> same follows with var for calling in .tf file
	or
	locals.instance_prefix
	or
	locals.comman_tags.company
	or 
	referencing from variable.tf
	locals{
	comman_tags = {
	  company = "var.company"
	  project = "${var.company}-${var.project}"
	  billing_code = "var.billing.code"
	}
   }
   
9-Now in main.tf conifgure variable and local_values .
10-OUTPUT_values :- It comes when the terraform is applied we saw the ouptut values in the console.
    Syntax
	 output "name_label" {
	  value = output_values
	  description = "Description can be any thing for ouptut"
	  sensitive = True | Fales
	  }
11-Syntax_Validation :- It's a best way to check the syntax is correct or not it'll also suggest before deployments.
    a-terraform-validate first
	b-check syntax and logic
	c-Does not check the current state
	d-No gurantee of deployment
	
	terraform -validate ---> terraform -init ---> terraform -plan ---> terraform -apply
	
12-Supply variable_values
   It can be declare in 6 ways and it goes from down to bottom here, technically left to right to make it win of evalaution
    -Default
	-var flag
	-var-file flag
	-terraform.tfvars
	 terraform.tfvars.json
	-auto.tfvars
	 auto.tfvars.json
	-variable TF_VAR_ 
13-Create variable.tfvars for storing values in same directory where main.tf and other tf files are present.
    Syntax or ex
	  billing code = ""
	  project = " "
	  
	for storing access key and secret key it can be placed in enviornment whether it is linux/windows machine
	windows declaring variable in var.tf
	   
			$env: TF_VAR_aws_access_key=""
			$env: TF_VAR_aws_secret_key=""
	(Exporting is totally differeent)
			$Export env: TF_VAR_aws_access_key=""
			$Export env: TF_VAR_aws_secret_key=""
			
14-Add more resources on demand to meet your goal.
15-Terraform state data:- In general we never mess with this file in any env rather do things precautions.Here some
    commands for state 
	  - terraform state list
	  - terraform state show ADDRESS
	  - terraform state mv SOURCE DESTINATION
	  - terraform state rm ADDRESS
16-First rule of terraform make all the changes within Terraform.
17-Terraform Providers -  * Pubic and private registers
                          * Official, Verified and community
						  * Open source
						  * Versioned
						  * Multiple Instances
						  
18-Terraform Block syntax for particaular provider on demand.In that case provider.tf file is been created where state and metadata
     in syntax is written.
	 
	 Syntax- terraform{
	      required provider {
		  provider name = {
             source = "address_to_provider"		  
		      #=,<,>, and ~>
		  version = "version_expression" 
		    }
		} 
	}
	  
	 Ex-
	    terraform{
	      required provider {
		   aws = {
             source = "harshicorp/aws"		  
		       version = "~>3.0" 
		    }
		} 
	}
	
	Provider block_alias syntax- 
	                             provider "provider_name" {
	                             alias = "alias_name"
								 #Provider specific arguments
							}
						  
		Example- (For particaular instance differeent region in aws provider) 
		     
			 provider "aws"	{
		     alias = "west"
			 #Provider specific arguments
		}
		resource "aws_instance" "web_server" {
		provider = "aws.west"
		#Resource sepcified arguments
        type = "string"		
		description = ""
		default = ""
		}
19-Process during terraform planning
		-Refresh and inspect state
		-Dependency graph
		-Addition,updates and deletion
		-Parallel execution
   Terraform itslef find the determining dependencies with telling how ec2 depends on s3 or subnets on vpc's
20-Post_Deployment_Configuration:- It is required sometimes for depoying over VM or Container or writing for sql servers or for native
   clients.We can create resource file for that for an ex- cluster for mysql database using mysql provider.
		Congiuration Options -Resource
							 -Pass Data
							 -Config Manager (Like chef,ansible,puppet)
							 -Provisioners :- -Defined in resource
							                  -Creation or destruction
											  -Multiple provisioners
											  -null_resource
											  -Failure option (If declare this terraform will go without telling any failures.)
											  -Last Resort!
							There are three provisioners types :- file(remote provisioners), local_exec(Locally provisioning),
							                                      remote_exec(It allows to run scripts over remote machines)
21-Formatting all the terraform files including the paths by using terraform -fmt 
22-Potential Improvments using loops and functions in the existing configuration file.
  
   ~>Looping 
      -loops construct [1,2,3] count integer (It can be used when same type of resource value is existing like in case of ec2,subnets,target groups.)
		
		Count_Syntax Example- intance.tf
						resource "aws_instance" "web_server" {
						count = 4
						tags =  {
						name =  "global-web-${count.index}"
								}						
						}
	    Count Refernces
			<resource_type>.<name_label>[elements].<attribute>
		     aws_instance.web_server[0].name #Single instance
			 aws_instance.web_server[*].name #All instance
			 
      -for_each (it is used for modules and resources it takes set or map as a value like each intance has different operation)
		
		Syntax Example- s3.tf
				resource "aws_s3_bucket_object" "sahi-paneer"{
					for_each = {
					paneer = "paneer.png"
					sahi-masala = "sahi-masala.png"
					}
					key = for_each
					source = ".${each.value}"
					tags = {
					name = "each.key"
					}
				}        (Note-Set is unordered set of collection and list and tuple are ordered collection)
		
		For_each Refernce
			<resource>.<name_label>.[key].<attribute>
			aws_s3_bucket_object.sahi-paneer[panner].id #single instance
			aws_s3_bucket_object.sahi-paneer[*].id #all instance
						
      -dynamic_block (it is used to create multiple instances in nested block inside apprant object it accepts map or set as a value)
23-Terraform functions and expressions
    Expressions->Interpolation and heredoc
	             Arithmetic and logical operators
				 Conditional Expressions
				 For expression
				 
	Functions->Built in terraform
	           Funct_name(args1,args2,args3,...)
			   Test in terraform console
			   Severeal broad categories
			   
	Common Functions Categories->Numeric min(10,20,30)
	                             String lower ("TACOS")
								 Collection merge("map1,map2")
								 IP Network cidrsubnet
								 File system file(path)
								 Type Conversion toset()
								 ........goes_on or find in registry.terraform.io
 
    Funtions to use-First initialize the terraform main.tf then try to use console by entring terraform console.For
	                example we can try-: min(20,9,40,45,12)
					                     >9
										 lower("FUCKYOU")
										 >fuckyou
										 cidrsubnet(var.vpc_cidr_block,8,0)
										 >"10.0.0.0/24"
										 lookup(local.comman_tags,"company","unkown")
										 >"Globomantics"
										 local.common.tags
										 >{
										  billing_code=""
										  company=""
										  project=""
										  }
24-Create template file seprate for intances by any name like- startup_script.tpl and define the path of this in user data resource of aws_intance
   by user_data = templatefile("${path.module}/file.name.with extension",{
       s3_bucket_name = aws_s3_bucket_object.id
	   })
25-Module--> -Components inputs---->Resources Data sources---->Outputs
             -Code reuse
			 -Remote or local source
			 -Versioning
			 -Terraform -init
			 -Multiple intance
       
	        [code_dev] 
			  | 
			  |
			  Root                |---(Folder)			       |---(Folder)
			  |                   |       |                    |
			  |                   |       |                    |   
			  |                   |       |                    |
			  |-->HCL file        |       |-->HCL file         |-->HCL file
			  |                   |       |                    |
			  |-->json file       |       |-->json file        |-->json file
			  |                   |       |                    |
			  |-->folder       ---|       |-->folder        ---|
			      (conatining_                (conatining_
				   child_modules)              child_modules)
 
    Consider root--->load_balancer---> 1)vpc
	                                   2)ec2
									   
26-Module Structure-> s3/main.tf
                      variable "bucket_name"
					  resource "aws.s3_bucket" {
					    name = "var.bucket_name"
					    []
					  }
					  Output "bucket_id"{
					    value = aws_s3_bucket.bucket.id
					  }
				
   Scoping->Child moudle cannot access resource and local values unitl its been passed in form of input_variables,therefore parent
             module cannot access outputs of child until its been send in form of output_values by the child_modules.

27-Module Syntax-> s3.tf
                   
                   module "name_label"{
				    source = "local_or_remote_source"
				    version = "version_expression"
					provider = {
					  moudle_provider = "parent_provider"
					}
					#inputs_values
				   }				   
				      
                Ex- moudle "sahi_paneer" {
				     source = ".s3/"   
					 }
					#inputs_values 
					bucket_name = "mah_bucket"
				}

	Module_References-	moudle.<name_label>.<ouptut_name>
                        moudle.sahi-paneer.bucket_id
						
28-For_expressions-> -Input_types--> List,set,tuple,map,or object
                     -Result_types-->Tuple or object
                     -Filtering with IF Statement	
     
    for_tuple_syntax-> #create a tuple
                       [ for item in items : tuple_elements]

                       Ex- locals{
					          toppings = ["chesse","lettuce","paneer"]
					   }					   
                       [for t in local.toppings : "Globo $(t)"]
                       
                       #Results
                         ["Globo chesse","Globo lettuce","Globo paneer"]
						 
	for_object_syntax-> #create an object
                         {for key, value in map : obj_key=> obj_key}

                        EX- locals{
						      prices = {
							   taco = ""
							   burito = ""
							   paneer = ""
							  }
						}
                        {for i, p in local.prices : i=>ceil(p)}
                       
                        #Results
                          {taco = "6",burito = "5",paneer = "300"}	

29-For applying confirm first that you are not working in production as using modules and initializing and applying it may destroy
   previous version of that,so in that case we can use terraform state mv. Here we can move from parent moudle to child_modules.

30-Worksapces-> Multiple Environment
                         |
						 |
				--------------------
				|        |          |
	   Development      UAT        Production
 	      \              |           /
		   \             |          /
		    \            |         /
			 \           |        /
			  \          |       /
			 (folder_conatining_tf_file)
	
	Terraform_workspaces-> -Commonality and differences
	                       -absrtraction and reuse
						   -Production access
						   -Using workspaces
						   
	Multiple Evnvironment Decisions-> State_Management
	                                  Variables_values
									  Credenitial_Management
									  Complexity and overhead

	State file example - terraform plan -state = ".\dev\dev.state"
	                     -var-file="comman.tfvars"
						 -var-file=".\dev\dev.tfvars"

    Worksapces_Example - *.tf files-terraform.tfvars 
	                     terraform.tfstate.d
						 
				        (It use the same root directory and with these two filw we can work in differeent envs.)
		
	Creating terraform workspace by using -terraform workspace new development and then -terraform plan.If you want to check in env you are
    just open terraform console by entering the same in CLI where your root directory consits and then write terraform workspace.It
	will tell you the current env.To check list terraform workspace list and to select the env from the list use 
	terraform workspace select development. Note-> Development is an ex it can be uat or preprod.

    Sensitive Values - It can be stored in variable_file,Environment variables,or in secret service. For hiding secret key and acccess key is to
                       export them into $env of the machine.	
					   
					   ******************ENDED********************